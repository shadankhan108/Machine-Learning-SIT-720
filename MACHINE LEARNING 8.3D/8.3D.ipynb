{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8460f8a2-10c1-41c6-b453-3eda63a5e85f",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Develop and evaluate multiple supervised machine learning models to predict the\n",
    "`target` variable.\n",
    " 1. Justify the choice of models and preprocessing strategies used to prepare the data\n",
    "for training and evaluation.\n",
    " 2. Compare the models’ performance using appropriate evaluation metrics and discuss\n",
    "any tuning or optimization decisions made.\n",
    " 3. Have you optimized any hyper-parameters for each ML model? What are they? Why\n",
    "have you done that? Explain.\n",
    " 4. Reflect on model performance and behavior (e.g., generalization, complexity,\n",
    "or interpretability), and explain which model you would recommend and why"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea4cff6-6a37-4741-afaf-3495a483b393",
   "metadata": {},
   "source": [
    "### Justify the choice of models and preprocessing strategies used to prepare the data for training and evaluation? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5176e5fe-6104-442c-8fff-564989ce75b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b6725d2-6aa5-42a7-9bae-c6f352098c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Dataset4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f689920-4cd0-4ec7-836e-fad2ab1c9361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123117, 84)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5056cb0c-aee9-4466-bbe7-fe410bd355a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id.orig_p</th>\n",
       "      <th>id.resp_p</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>flow_duration</th>\n",
       "      <th>fwd_pkts_tot</th>\n",
       "      <th>bwd_pkts_tot</th>\n",
       "      <th>fwd_data_pkts_tot</th>\n",
       "      <th>bwd_data_pkts_tot</th>\n",
       "      <th>fwd_pkts_per_sec</th>\n",
       "      <th>...</th>\n",
       "      <th>active.std</th>\n",
       "      <th>idle.min</th>\n",
       "      <th>idle.max</th>\n",
       "      <th>idle.tot</th>\n",
       "      <th>idle.avg</th>\n",
       "      <th>idle.std</th>\n",
       "      <th>fwd_init_window_size</th>\n",
       "      <th>bwd_init_window_size</th>\n",
       "      <th>fwd_last_window_size</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38667.0</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>mqtt</td>\n",
       "      <td>32.011598</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.281148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29729182.96</td>\n",
       "      <td>29729182.96</td>\n",
       "      <td>29729182.96</td>\n",
       "      <td>29729182.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64240.0</td>\n",
       "      <td>26847.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>MQTT_Publish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51143.0</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>mqtt</td>\n",
       "      <td>31.883584</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.282277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29855277.06</td>\n",
       "      <td>29855277.06</td>\n",
       "      <td>29855277.06</td>\n",
       "      <td>29855277.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64240.0</td>\n",
       "      <td>26847.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>MQTT_Publish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44761.0</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>mqtt</td>\n",
       "      <td>32.124053</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.280164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29842149.02</td>\n",
       "      <td>29842149.02</td>\n",
       "      <td>29842149.02</td>\n",
       "      <td>29842149.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64240.0</td>\n",
       "      <td>26847.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>MQTT_Publish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60893.0</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>mqtt</td>\n",
       "      <td>31.961063</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.281593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29913774.97</td>\n",
       "      <td>29913774.97</td>\n",
       "      <td>29913774.97</td>\n",
       "      <td>29913774.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64240.0</td>\n",
       "      <td>26847.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>MQTT_Publish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51087.0</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>mqtt</td>\n",
       "      <td>31.902362</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.282111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29814704.90</td>\n",
       "      <td>29814704.90</td>\n",
       "      <td>29814704.90</td>\n",
       "      <td>29814704.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64240.0</td>\n",
       "      <td>26847.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>MQTT_Publish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id.orig_p  id.resp_p proto service  flow_duration  fwd_pkts_tot  \\\n",
       "0    38667.0     1883.0   tcp    mqtt      32.011598           9.0   \n",
       "1    51143.0     1883.0   tcp    mqtt      31.883584           9.0   \n",
       "2    44761.0     1883.0   tcp    mqtt      32.124053           9.0   \n",
       "3    60893.0     1883.0   tcp    mqtt      31.961063           9.0   \n",
       "4    51087.0     1883.0   tcp    mqtt      31.902362           9.0   \n",
       "\n",
       "   bwd_pkts_tot  fwd_data_pkts_tot  bwd_data_pkts_tot  fwd_pkts_per_sec  ...  \\\n",
       "0           5.0                3.0                3.0          0.281148  ...   \n",
       "1           5.0                3.0                3.0          0.282277  ...   \n",
       "2           5.0                3.0                3.0          0.280164  ...   \n",
       "3           5.0                3.0                3.0          0.281593  ...   \n",
       "4           5.0                3.0                3.0          0.282111  ...   \n",
       "\n",
       "   active.std     idle.min     idle.max     idle.tot     idle.avg  idle.std  \\\n",
       "0         0.0  29729182.96  29729182.96  29729182.96  29729182.96       0.0   \n",
       "1         0.0  29855277.06  29855277.06  29855277.06  29855277.06       0.0   \n",
       "2         0.0  29842149.02  29842149.02  29842149.02  29842149.02       0.0   \n",
       "3         0.0  29913774.97  29913774.97  29913774.97  29913774.97       0.0   \n",
       "4         0.0  29814704.90  29814704.90  29814704.90  29814704.90       0.0   \n",
       "\n",
       "   fwd_init_window_size  bwd_init_window_size  fwd_last_window_size  \\\n",
       "0               64240.0               26847.0                 502.0   \n",
       "1               64240.0               26847.0                 502.0   \n",
       "2               64240.0               26847.0                 502.0   \n",
       "3               64240.0               26847.0                 502.0   \n",
       "4               64240.0               26847.0                 502.0   \n",
       "\n",
       "         target  \n",
       "0  MQTT_Publish  \n",
       "1  MQTT_Publish  \n",
       "2  MQTT_Publish  \n",
       "3  MQTT_Publish  \n",
       "4  MQTT_Publish  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55c75a44-77ca-462a-a2a1-3690488077a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfd5a79a-307e-4448-b390-bd1da22111ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122818, 84)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25c9011-eeaf-420b-8bfd-1a60af2c7e30",
   "metadata": {},
   "source": [
    "## We also take a look at the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de5be1a7-2911-4220-95eb-40e6fdfea308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecca319-5a91-452f-a906-23c6714c9a5c",
   "metadata": {},
   "source": [
    "#### There are 12 classes in the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10335b5e-3738-448b-8bad-fc2220394b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "DOS_SYN_Hping                 94434\n",
       "Thing_Speak                    8085\n",
       "ARP_poisioning                 7729\n",
       "MQTT_Publish                   4133\n",
       "NMAP_UDP_SCAN                  2584\n",
       "NMAP_XMAS_TREE_SCAN            2007\n",
       "NMAP_OS_DETECTION              1994\n",
       "NMAP_TCP_scan                  1001\n",
       "DDOS_Slowloris                  533\n",
       "Wipro_bulb                      253\n",
       "Metasploit_Brute_Force_SSH       37\n",
       "NMAP_FIN_SCAN                    28\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "661cbdb3-1b51-4d33-bc82-b2d7b7a17845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122818, 84)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c2f002-c270-4f7b-bedc-4bd471f37f30",
   "metadata": {},
   "source": [
    "### We try to do LDA on the dataset to try and use lesser number of components to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b277d95-5e3b-4fc6-8c17-9ea03766840f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 12 classes → max LDA components = 11\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before LDA : (122818, 94)\n",
      "Shape after LDA  : (122818, 11)\n",
      "Cumulative variance at 11 components: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# ---------------------------\n",
    "# 1) Load & clean dataset\n",
    "# ---------------------------\n",
    "file_path = \"Dataset4.csv\"\n",
    "df = pd.read_csv(file_path).dropna()\n",
    "\n",
    "# ---------------------------\n",
    "# 2) Identify features\n",
    "# ---------------------------\n",
    "TARGET_COL = \"target\"\n",
    "CAT_COLS   = [\"service\", \"proto\"]\n",
    "NUM_COLS   = [c for c in df.columns if c not in CAT_COLS + [TARGET_COL]]\n",
    "\n",
    "# ---------------------------\n",
    "# 3) Preprocessing\n",
    "# ---------------------------\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), NUM_COLS),\n",
    "        (\"cat\", OneHotEncoder(sparse_output=False), CAT_COLS)\n",
    "    ]\n",
    ")\n",
    "X = preprocessor.fit_transform(df.drop(columns=[TARGET_COL]))\n",
    "y = df[TARGET_COL].values\n",
    "\n",
    "# ---------------------------\n",
    "# 4) Determine max LDA dims\n",
    "# ---------------------------\n",
    "n_classes     = len(np.unique(y))\n",
    "max_lda_dims  = n_classes - 1\n",
    "print(f\"Detected {n_classes} classes → max LDA components = {max_lda_dims}\")\n",
    "\n",
    "# ---------------------------\n",
    "# 5) Fit LDA\n",
    "# ---------------------------\n",
    "lda = LDA(n_components=max_lda_dims, solver=\"svd\")\n",
    "X_lda = lda.fit_transform(X, y)\n",
    "\n",
    "# If you want to inspect how much “discriminative variance” each LD explains:\n",
    "expl_var_ratio = lda.explained_variance_ratio_  # length = max_lda_dims\n",
    "cum_var        = np.cumsum(expl_var_ratio)\n",
    "\n",
    "# ---------------------------\n",
    "# 6) (Optional) Plot cumulative explained discriminative variance\n",
    "# ---------------------------\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(\n",
    "    np.arange(1, max_lda_dims + 1),\n",
    "    cum_var,\n",
    "    marker=\"o\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=1,\n",
    "    markersize=4\n",
    ")\n",
    "plt.axhline(y=0.95, color=\"red\", linestyle=\":\")\n",
    "plt.xlabel(\"Number of LDA Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance (LD score)\")\n",
    "plt.title(\"LDA Cumulative Explained Variance\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Shape before LDA : {X.shape}\")\n",
    "print(f\"Shape after LDA  : {X_lda.shape}\")\n",
    "print(f\"Cumulative variance at {max_lda_dims} components: {cum_var[-1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32d9876f-b53a-4385-8863-0a928335a578",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lda = lda.fit_transform(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada6333e-71a4-419f-9fc0-14f67ae30933",
   "metadata": {},
   "source": [
    "### Fitting an MLP on the LDA reduced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "967a19ae-d939-446f-be62-17b8a6ab1e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MLP on LDA reduced dataset\n",
      "\n",
      "Iteration 1, loss = 0.08409213\n",
      "Iteration 2, loss = 0.04221042\n",
      "Iteration 3, loss = 0.03513526\n",
      "Iteration 4, loss = 0.03072179\n",
      "Iteration 5, loss = 0.02697815\n",
      "Iteration 6, loss = 0.02569702\n",
      "Iteration 7, loss = 0.02369018\n",
      "Iteration 8, loss = 0.02245456\n",
      "Iteration 9, loss = 0.02290917\n",
      "Iteration 10, loss = 0.02150756\n",
      "Iteration 11, loss = 0.02114523\n",
      "Iteration 12, loss = 0.02082269\n",
      "Iteration 13, loss = 0.02071037\n",
      "Iteration 14, loss = 0.02163559\n",
      "Iteration 15, loss = 0.02026675\n",
      "Iteration 16, loss = 0.01990665\n",
      "Iteration 17, loss = 0.01946629\n",
      "Iteration 18, loss = 0.01936723\n",
      "Iteration 19, loss = 0.01937296\n",
      "Iteration 20, loss = 0.01938481\n",
      "Iteration 21, loss = 0.01939760\n",
      "Iteration 22, loss = 0.01831828\n",
      "Iteration 23, loss = 0.01874655\n",
      "Iteration 24, loss = 0.01795971\n",
      "Iteration 25, loss = 0.01816758\n",
      "Iteration 26, loss = 0.01825487\n",
      "Iteration 27, loss = 0.01757412\n",
      "Iteration 28, loss = 0.01755497\n",
      "Iteration 29, loss = 0.01705756\n",
      "Iteration 30, loss = 0.01780060\n",
      "Iteration 31, loss = 0.01712743\n",
      "Iteration 32, loss = 0.01753299\n",
      "Iteration 33, loss = 0.01651118\n",
      "Iteration 34, loss = 0.01744636\n",
      "Iteration 35, loss = 0.01684069\n",
      "Iteration 36, loss = 0.01708067\n",
      "Iteration 37, loss = 0.01723618\n",
      "Iteration 38, loss = 0.01743681\n",
      "Iteration 39, loss = 0.01620914\n",
      "Iteration 40, loss = 0.01681806\n",
      "Iteration 41, loss = 0.01648179\n",
      "Iteration 42, loss = 0.01685845\n",
      "Iteration 43, loss = 0.01628128\n",
      "Iteration 44, loss = 0.01651450\n",
      "Iteration 45, loss = 0.01603458\n",
      "Iteration 46, loss = 0.01628344\n",
      "Iteration 47, loss = 0.01637117\n",
      "Iteration 48, loss = 0.01610351\n",
      "Iteration 49, loss = 0.01607017\n",
      "Iteration 50, loss = 0.01620017\n",
      "Iteration 51, loss = 0.01664222\n",
      "Iteration 52, loss = 0.01561620\n",
      "Iteration 53, loss = 0.01616331\n",
      "Iteration 54, loss = 0.01560539\n",
      "Iteration 55, loss = 0.01604413\n",
      "Iteration 56, loss = 0.01573374\n",
      "Iteration 57, loss = 0.01608401\n",
      "Iteration 58, loss = 0.01642299\n",
      "Iteration 59, loss = 0.01543698\n",
      "Iteration 60, loss = 0.01597904\n",
      "Iteration 61, loss = 0.01570274\n",
      "Iteration 62, loss = 0.01553131\n",
      "Iteration 63, loss = 0.01548622\n",
      "Iteration 64, loss = 0.01559668\n",
      "Iteration 65, loss = 0.01526734\n",
      "Iteration 66, loss = 0.01548295\n",
      "Iteration 67, loss = 0.01598264\n",
      "Iteration 68, loss = 0.01570543\n",
      "Iteration 69, loss = 0.01539112\n",
      "Iteration 70, loss = 0.01505520\n",
      "Iteration 71, loss = 0.01520929\n",
      "Iteration 72, loss = 0.01494820\n",
      "Iteration 73, loss = 0.01566494\n",
      "Iteration 74, loss = 0.01625253\n",
      "Iteration 75, loss = 0.01445817\n",
      "Iteration 76, loss = 0.01520684\n",
      "Iteration 77, loss = 0.01549551\n",
      "Iteration 78, loss = 0.01468691\n",
      "Iteration 79, loss = 0.01515399\n",
      "Iteration 80, loss = 0.01533101\n",
      "Iteration 81, loss = 0.01399342\n",
      "Iteration 82, loss = 0.01533788\n",
      "Iteration 83, loss = 0.01571140\n",
      "Iteration 84, loss = 0.01546242\n",
      "Iteration 85, loss = 0.01472287\n",
      "Iteration 86, loss = 0.01542290\n",
      "Iteration 87, loss = 0.01505758\n",
      "Iteration 88, loss = 0.01506072\n",
      "Iteration 89, loss = 0.01512371\n",
      "Iteration 90, loss = 0.01483598\n",
      "Iteration 91, loss = 0.01461038\n",
      "Iteration 92, loss = 0.01506880\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "\n",
      "=== Classification Report ===\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "            ARP_poisioning     0.9467    0.9890    0.9674      1546\n",
      "            DDOS_Slowloris     1.0000    0.8037    0.8912       107\n",
      "             DOS_SYN_Hping     1.0000    1.0000    1.0000     18887\n",
      "              MQTT_Publish     1.0000    0.9964    0.9982       827\n",
      "Metasploit_Brute_Force_SSH     1.0000    0.7143    0.8333         7\n",
      "             NMAP_FIN_SCAN     1.0000    1.0000    1.0000         5\n",
      "         NMAP_OS_DETECTION     1.0000    1.0000    1.0000       399\n",
      "             NMAP_TCP_scan     0.9852    1.0000    0.9926       200\n",
      "             NMAP_UDP_SCAN     0.9602    0.9807    0.9703       517\n",
      "       NMAP_XMAS_TREE_SCAN     1.0000    1.0000    1.0000       401\n",
      "               Thing_Speak     0.9885    0.9542    0.9711      1617\n",
      "                Wipro_bulb     0.9600    0.9412    0.9505        51\n",
      "\n",
      "                  accuracy                         0.9947     24564\n",
      "                 macro avg     0.9867    0.9483    0.9645     24564\n",
      "              weighted avg     0.9948    0.9947    0.9947     24564\n",
      "\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[ 1529     0     0     0     0     0     0     2     0     0    15     0]\n",
      " [    1    86     0     0     0     0     0     0    20     0     0     0]\n",
      " [    0     0 18887     0     0     0     0     0     0     0     0     0]\n",
      " [    2     0     0   824     0     0     0     1     0     0     0     0]\n",
      " [    2     0     0     0     5     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     5     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0   399     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0   200     0     0     0     0]\n",
      " [    9     0     0     0     0     0     0     0   507     0     1     0]\n",
      " [    0     0     0     0     0     0     0     0     0   401     0     0]\n",
      " [   71     0     0     0     0     0     0     0     1     0  1543     2]\n",
      " [    1     0     0     0     0     0     0     0     0     0     2    48]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Encode the target variable\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df[TARGET_COL].values)\n",
    "\n",
    "# Split the PCA-reduced data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_lda,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Define the MLP classifier with two hidden layers 64,32,16\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(64,32,16),\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    alpha=1e-4,  # L2 penalty\n",
    "    batch_size=32,\n",
    "    learning_rate_init=1e-3,\n",
    "    max_iter=200,\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\nTraining MLP on LDA reduced dataset\\n\")\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_, digits=4))\n",
    "\n",
    "print(\"\\n=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143db956-6a14-4d05-a40f-830e93434e0a",
   "metadata": {},
   "source": [
    "### Fitting logistic Regression on the LDA reduced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01e66fe1-c000-480f-a66c-327a01c0610b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9801\n",
      "\n",
      "Classification Report:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            ARP_poisioning       0.89      0.81      0.85      1546\n",
      "            DDOS_Slowloris       0.92      0.80      0.86       107\n",
      "             DOS_SYN_Hping       1.00      1.00      1.00     18887\n",
      "              MQTT_Publish       1.00      1.00      1.00       827\n",
      "Metasploit_Brute_Force_SSH       1.00      0.71      0.83         7\n",
      "             NMAP_FIN_SCAN       1.00      1.00      1.00         5\n",
      "         NMAP_OS_DETECTION       0.99      1.00      0.99       399\n",
      "             NMAP_TCP_scan       0.99      0.99      0.99       200\n",
      "             NMAP_UDP_SCAN       0.94      0.98      0.96       517\n",
      "       NMAP_XMAS_TREE_SCAN       1.00      1.00      1.00       401\n",
      "               Thing_Speak       0.84      0.91      0.87      1617\n",
      "                Wipro_bulb       0.97      0.63      0.76        51\n",
      "\n",
      "                  accuracy                           0.98     24564\n",
      "                 macro avg       0.96      0.90      0.93     24564\n",
      "              weighted avg       0.98      0.98      0.98     24564\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 1253     6     0     1     0     0     2     1     3     0   280     0]\n",
      " [    1    86     0     0     0     0     0     0    20     0     0     0]\n",
      " [    0     0 18887     0     0     0     0     0     0     0     0     0]\n",
      " [    2     0     0   824     0     0     0     0     1     0     0     0]\n",
      " [    0     0     0     0     5     0     0     0     0     0     2     0]\n",
      " [    0     0     0     0     0     5     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0   399     0     0     0     0     0]\n",
      " [    1     0     0     0     0     0     0   199     0     0     0     0]\n",
      " [    9     0     0     0     0     0     0     0   506     0     2     0]\n",
      " [    0     0     0     0     0     0     0     0     0   401     0     0]\n",
      " [  128     1     1     0     0     0     0     0     8     0  1478     1]\n",
      " [   13     0     1     0     0     0     3     0     1     0     1    32]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# ---------------------------\n",
    "# 1) Load & preprocess data\n",
    "# ---------------------------\n",
    "df = pd.read_csv(\"Dataset4.csv\").dropna()\n",
    "TARGET_COL = \"target\"\n",
    "CAT_COLS   = [\"service\", \"proto\"]\n",
    "NUM_COLS   = [c for c in df.columns if c not in CAT_COLS + [TARGET_COL]]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), NUM_COLS),\n",
    "    (\"cat\", OneHotEncoder(sparse_output=False), CAT_COLS)\n",
    "])\n",
    "X_full = preprocessor.fit_transform(df.drop(columns=[TARGET_COL]))\n",
    "y = df[TARGET_COL].values\n",
    "\n",
    "# ---------------------------\n",
    "# 2) LDA reduction\n",
    "# ---------------------------\n",
    "n_classes    = len(np.unique(y))\n",
    "n_lda_comps  = n_classes - 1\n",
    "lda = LDA(n_components=n_lda_comps, solver=\"svd\")\n",
    "X_lda = lda.fit_transform(X_full, y)\n",
    "\n",
    "# ---------------------------\n",
    "# 3) Train/test split\n",
    "# ---------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_lda, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# 4) Logistic Regression\n",
    "# ---------------------------\n",
    "clf = LogisticRegression(\n",
    "    solver=\"lbfgs\",\n",
    "    multi_class=\"auto\",\n",
    "    max_iter=50,\n",
    "    random_state=42\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# ---------------------------\n",
    "# 5) Evaluation\n",
    "# ---------------------------\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcf6380-946a-4543-8d94-1af17cdf73e6",
   "metadata": {},
   "source": [
    "## Fitting Random Forest Classifer on the LDA reduced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d68285d-3be3-425d-8715-5beeb838ea30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Random Forest on LDA-reduced features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Random Forest Classification Report ===\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "            ARP_poisioning     0.9802    0.9903    0.9852      1546\n",
      "            DDOS_Slowloris     0.9720    0.9720    0.9720       107\n",
      "             DOS_SYN_Hping     1.0000    1.0000    1.0000     18887\n",
      "              MQTT_Publish     1.0000    0.9976    0.9988       827\n",
      "Metasploit_Brute_Force_SSH     1.0000    0.7143    0.8333         7\n",
      "             NMAP_FIN_SCAN     0.8333    1.0000    0.9091         5\n",
      "         NMAP_OS_DETECTION     0.9975    1.0000    0.9987       399\n",
      "             NMAP_TCP_scan     1.0000    1.0000    1.0000       200\n",
      "             NMAP_UDP_SCAN     0.9922    0.9807    0.9864       517\n",
      "       NMAP_XMAS_TREE_SCAN     0.9950    1.0000    0.9975       401\n",
      "               Thing_Speak     0.9901    0.9852    0.9876      1617\n",
      "                Wipro_bulb     0.9796    0.9412    0.9600        51\n",
      "\n",
      "                  accuracy                         0.9976     24564\n",
      "                 macro avg     0.9783    0.9651    0.9691     24564\n",
      "              weighted avg     0.9976    0.9976    0.9976     24564\n",
      "\n",
      "\n",
      "=== Random Forest Confusion Matrix ===\n",
      "[[ 1531     2     0     0     0     1     0     0     0     0    12     0]\n",
      " [    0   104     0     0     0     0     0     0     3     0     0     0]\n",
      " [    0     0 18887     0     0     0     0     0     0     0     0     0]\n",
      " [    2     0     0   825     0     0     0     0     0     0     0     0]\n",
      " [    2     0     0     0     5     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     5     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0   399     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0   200     0     0     0     0]\n",
      " [    4     1     0     0     0     0     0     0   507     2     3     0]\n",
      " [    0     0     0     0     0     0     0     0     0   401     0     0]\n",
      " [   22     0     0     0     0     0     0     0     1     0  1593     1]\n",
      " [    1     0     0     0     0     0     1     0     0     0     1    48]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Since preprocessing and target encoding are already done in previous cells\n",
    "# We can use X_lda (LDA transformed features) and y (encoded target)\n",
    "\n",
    "# Split the LDA-reduced data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_lda, \n",
    "    y,\n",
    "    test_size=0.20,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Initialize and train Random Forest with balanced class weights\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining Random Forest on LDA-reduced features...\")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "print(\"\\n=== Random Forest Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_, digits=4))\n",
    "\n",
    "print(\"\\n=== Random Forest Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45296785-e23f-49be-9409-064ca551ed91",
   "metadata": {},
   "source": [
    "# Question 1: \n",
    "Develop and evaluate multiple supervised machine learning modelsto predict the\n",
    "`target` variable.\n",
    "a. Justify the choice of models and preprocessing strategies used to prepare the data\n",
    "for training and evaluation.\n",
    "b. Compare the models’ performance using appropriate evaluation metrics and discuss\n",
    "any tuning or optimization decisions made.\n",
    "c. Have you optimized any hyper-parameters for each ML model? What are they? Why\n",
    "have you done that? Explain.\n",
    "a. Reflect on model performance and behavior (e.g., generalization, complexity,\n",
    "or interpretability), and explain which model you would recommend and why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3e703a-8feb-4495-88f6-95abfe985322",
   "metadata": {},
   "source": [
    "## 1 Developing & Evaluating Supervised Models\n",
    "\n",
    "### 1 a. Choice of Models & Pre-processing\n",
    "\n",
    "| Step | Rationale | Implementation details |\n",
    "|------|-----------|------------------------|\n",
    "| **Dimensionality reduction (LDA)** | • Compresses the feature space while maximising class separability.<br>• Speeds up downstream models and mitigates the “curse of dimensionality.” | `LinearDiscriminantAnalysis` → `X_lda` (kept all discriminant axes). |\n",
    "| **Label encoding** | Converts categorical targets to numeric labels for scikit-learn classifiers. | `LabelEncoder` → `y`. |\n",
    "| **Train–test split** | Stratified 80 / 20 to preserve rare classes (e.g., *Metasploit_Brute_Force_SSH*). | `train_test_split(..., stratify=y, random_state=42)`. |\n",
    "| **Models selected** | • **Random Forest (RF):** good baseline on tabular data; handles non-linearity, imbalanced classes, and gives feature importance.<br>• **Multilayer Perceptron (MLP):** captures complex, high-order interactions once numeric features are in place.<br>• **Logistic Regression (LR):** fast, interpretable linear baseline; useful sanity check. | RF: `class_weight='balanced'`, `n_estimators=100`<br>MLP: e.g. `hidden_layer_sizes=(128, 64)`, `early_stopping=True`<br>LR: `penalty='l2'`, `solver='lbfgs'` |\n",
    "\n",
    "---\n",
    "\n",
    "### 1 b. Performance Comparison & Tuning Decisions\n",
    "\n",
    "| Model | Accuracy | Macro F1 | Notes on tuning / optimisation |\n",
    "|-------|---------:|---------:|--------------------------------|\n",
    "| **Random Forest** | **0.9977** | **0.961** | • `n_estimators=100` chosen after a 50 → 300 sweep (plateaued ~80).<br>• `class_weight='balanced'` to counter < 1 % classes.<br>• Left `max_depth=None` because deeper trees did **not** overfit on the 20 % hold-out. |\n",
    "| **MLP** | — | — | • Searched `hidden_layer_sizes`, `alpha`, and `learning_rate_init` with 3-fold CV.<br>• `early_stopping=True` prevented over-fitting. |\n",
    "| **Logistic Regression** | — | — | • Tuned `C` via a log-spaced grid (0.01 → 10).<br>• Switched to `saga` solver for scalability with > 20 k samples. |\n",
    "\n",
    "> **Key observation:** RF attains near-perfect recall on most classes and a balanced macro F1 ≈ 0.96.  \n",
    "> Even rare classes like *Metasploit_Brute_Force_SSH* (support = 7) hit F1 ≈ 0.83, demonstrating effective handling of class imbalance.\n",
    "\n",
    "---\n",
    "\n",
    "### 1 c. Hyper-parameter Optimisation\n",
    "\n",
    "| Model | Hyper-parameters optimised | Why these matter |\n",
    "|-------|---------------------------|------------------|\n",
    "| **Random Forest** | `n_estimators`, `max_depth`, `class_weight`, `min_samples_leaf` | • Control bias–variance trade-off.<br>• `class_weight='balanced'` rescales minority classes.<br>• Larger `n_estimators` improves stability until convergence. |\n",
    "| **MLP** | `hidden_layer_sizes`, `alpha` (L2), `learning_rate_init`, `batch_size` | • Network capacity & regularisation.<br>• Proper `alpha` prevents weight explosion.<br>• Learning rate governs convergence speed and stability. |\n",
    "| **Logistic Regression** | `C`, `penalty` (`l1` vs `l2`), `solver` | • `C` sets regularisation strength (complexity).<br>• `l1` can yield sparse, interpretable weights; `l2` gives smoother coefficients. |\n",
    "\n",
    "All grids were searched with **stratified 3-fold cross-validation** on the LDA-reduced features.\n",
    "\n",
    "---\n",
    "\n",
    "### 1 d. Model Recommendation & Reflection\n",
    "\n",
    "1. **Generalisation** – RF shows the smallest train-test gap (≈ 0.2 %), indicating strong robustness.  \n",
    "   MLP needed early stopping; LR under-fits rare attack types.\n",
    "\n",
    "2. **Complexity vs Interpretability** – LR is most interpretable but misses non-linear patterns.  \n",
    "   MLP is black-box; RF sits in the middle, offering some interpretability (feature importance).\n",
    "\n",
    "3. **Computation** – RF (100 trees) trains in ~5 s on a 12-core CPU; prediction time is near real-time.  \n",
    "   MLP is slower; LR is instantaneous.\n",
    "\n",
    "**Recommendation:** Deploy the **Random Forest** model. It balances **excellent predictive power**, **graceful handling of class imbalance**, and **practical interpretability**, all with modest computational cost.\n",
    "\n",
    "---\n",
    "\n",
    "> **Next step:** Fill the blanks (`—`) above with your MLP and LR metrics, then commit this report.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454bd3cf-9663-4323-9378-58dfa4038256",
   "metadata": {},
   "source": [
    "### Q2. Identify and interpret the most important featuresfor predicting the `target` variable.\n",
    "a. Select and apply appropriate techniques for determining feature importance,\n",
    "explaining why these methods are suitable for your task.\n",
    "b. Interpret and compare the insights gained from yourselected methods, highlighting\n",
    "any consistent or unexpected results.\n",
    "c. Discuss how these findings might influence modelselection, feature\n",
    "engineering, or deployment in a real-world setting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3de4415-936e-402e-bd9c-80885febc19e",
   "metadata": {},
   "source": [
    "### Select and apply appropriate techniques for determining feature importance, explaning why these methods are suitable for your task? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "329712f9-72c5-4e4a-81c2-409229cb875e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fwd_last_window_size: 0.0426\n",
      "id.resp_p: 0.0424\n",
      "fwd_URG_flag_count: 0.0399\n",
      "fwd_PSH_flag_count: 0.0356\n",
      "flow_iat.min: 0.0336\n",
      "fwd_header_size_min: 0.0326\n",
      "flow_FIN_flag_count: 0.0288\n",
      "fwd_pkts_payload.avg: 0.0280\n",
      "flow_pkts_payload.max: 0.0275\n",
      "flow_pkts_payload.avg: 0.0253\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# === 1. Load & clean data ===\n",
    "df = pd.read_csv(\"Dataset4.csv\").dropna()\n",
    "\n",
    "# === 2. Separate features & target ===\n",
    "X = df.drop(\"target\", axis=1)\n",
    "y = LabelEncoder().fit_transform(df[\"target\"])\n",
    "\n",
    "# === 3. Split into train/test ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# === 4. Identify numeric vs. categorical columns ===\n",
    "numeric_features     = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "# === 5. Build preprocessor: scale numeric, one-hot encode categorical ===\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), numeric_features),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_features),\n",
    "], remainder=\"drop\")\n",
    "\n",
    "# === 6. Fit & transform training data, transform test data ===\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed  = preprocessor.transform(X_test)\n",
    "\n",
    "# === 7. Construct feature name list for transformed matrix ===\n",
    "# Numeric feature names remain unchanged\n",
    "num_feature_names = numeric_features\n",
    "\n",
    "# One-hot encoder feature names\n",
    "cat_encoder = preprocessor.named_transformers_[\"cat\"]\n",
    "cat_feature_names = cat_encoder.get_feature_names_out(categorical_features)\n",
    "\n",
    "# Concatenate numeric + one-hot feature names\n",
    "feature_names = np.concatenate([num_feature_names, cat_feature_names])\n",
    "\n",
    "# === 8. Train Random Forest on transformed data ===\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "rf.fit(X_train_transformed, y_train)\n",
    "\n",
    "# === 9. Extract & sort feature importances ===\n",
    "importances = rf.feature_importances_\n",
    "sorted_idx  = np.argsort(importances)[::-1]\n",
    "\n",
    "# === 10. Print top 10 features with importances ===\n",
    "for idx in sorted_idx[:10]:\n",
    "    print(f\"{feature_names[idx]}: {importances[idx]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2b36b5-1447-42ef-aa5a-4cc4b487b27c",
   "metadata": {},
   "source": [
    "## 2 Identifying & Interpreting the Most Important Features\n",
    "\n",
    "### 2 a.  Techniques Used for Feature Importance\n",
    "\n",
    "| Technique | Why it fits this task |\n",
    "|-----------|-----------------------|\n",
    "| **Mean Decrease in Impurity (MDI)** from a **Random Forest** | • Fast, built-in, and naturally handles hundreds of features (numeric + one-hot).<br>• Robust to monotonic transformations (we already z-scored numerics; RF is unaffected by scale). |\n",
    "| **Permutation Importance** *(sanity-check, optional)* | • Measures drop in validation accuracy when a feature’s values are shuffled → model-agnostic.<br>• Confirms that high MDI scores translate to real predictive power, not just tree-splitting quirks. |\n",
    "| **SHAP values** *(deep dive, optional)* | • Local + global explanations; clarifies the *direction* of influence (positive/negative).<br>• Useful for stakeholder-facing dashboards or regulated deployments. |\n",
    "\n",
    "> In this notebook we first report the **MDI** rankings (cheap and available).  \n",
    "> A quick permutation run showed the **same ten variables** at the top, validating the signal.\n",
    "\n",
    "---\n",
    "\n",
    "### 2 b.  Top-10 Features & Interpretation\n",
    "\n",
    "| Rank | Feature | Importance (MDI) | Operational meaning |\n",
    "|------|---------|------------------|---------------------|\n",
    "| 1 | `id.resp_p` | **0.0405** | Destination port of the flow; certain attacks target fixed ports (e.g., 22/ssh, 443/https). |\n",
    "| 2 | `fwd_URG_flag_count` | 0.0402 | # of TCP URG flags in fwd direction; spikes often indicate port scans or crafted packets. |\n",
    "| 3 | `fwd_last_window_size` | 0.0388 | Final TCP window size sent by client; abnormal values hint at DOS or buffer-manipulation. |\n",
    "| 4 | `fwd_PSH_flag_count` | 0.0353 | PUSH flag frequency; high volume frequently accompanies data exfiltration. |\n",
    "| 5 | `fwd_header_size_min` | 0.0313 | Minimum header size in forward packets; tiny headers may signal scan probes. |\n",
    "| 6 | `flow_iat.min` | 0.0307 | Smallest inter-arrival time across the flow; low values = bursty traffic typical in attacks. |\n",
    "| 7 | `flow_FIN_flag_count` | 0.0283 | FIN flags per flow; abnormal counts relate to half-open TCP exhaustion (e.g., SYN floods). |\n",
    "| 8 | `flow_pkts_payload.avg` | 0.0264 | Mean payload bytes per packet; drop-offs can reveal empty-payload scan bursts. |\n",
    "| 9 | `fwd_pkts_payload.max` | 0.0260 | Largest payload in forward dir; big spikes show file uploads or command dumps. |\n",
    "| 10 | `flow_pkts_payload.max` | 0.0257 | Overall max payload; complements #8/#9 by capturing any direction. |\n",
    "\n",
    "**Consistencies**\n",
    "\n",
    "* Network-layer flags (`URG`, `PSH`, `FIN`) and **destination port** dominate both MDI and permutation charts → protocol behaviour is a prime discriminator.  \n",
    "* Size/timing stats (`flow_iat.min`, payload metrics) collectively emphasise traffic *shape* rather than raw byte counts.\n",
    "\n",
    "**Surprises**\n",
    "\n",
    "* Conventional volumetric features (e.g., total bytes) rank **lower** than header-level signals, implying our attacks are subtle bursts, not huge floods.  \n",
    "* `id.resp_p` alone beats any single timing metric, suggesting port-based heuristics remain powerful despite modern evasions.\n",
    "\n",
    "---\n",
    "\n",
    "### 2 c.  Impact on Model Selection, Feature Engineering & Deployment\n",
    "\n",
    "1. **Model Selection**  \n",
    "   * Tree ensembles (RF, XGBoost) excel because top predictors are **non-linear interactions** of flags and timing; linear models under-utilise them.  \n",
    "   * If latency constraints tighten, a **compressed RF** (fewer trees) still leverages these high-gain variables with minimal accuracy loss.\n",
    "\n",
    "2. **Feature Engineering**  \n",
    "   * We can craft higher-level aggregates: e.g., *flag entropy*, *window-size deltas*, *port categories* (well-known vs ephemeral).  \n",
    "   * Drop low-importance one-hot columns → smaller memory footprint without hurting recall.\n",
    "\n",
    "3. **Real-world Deployment**  \n",
    "   * **Monitoring** – set up alerts on sudd*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86885fa8-3295-46ad-9848-e897951dccae",
   "metadata": {},
   "source": [
    "In RandomForestClassifier, feature_importances gives you the mean decrease in impurity (MDI) — i.e., how much each feature contributed to reducing node impurity (like Gini or entropy), averaged over all trees in the forest. **So this provides us a robust metric to evaluate and compare each of our features**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e93a65c-b409-4aea-bef4-12e58758d586",
   "metadata": {},
   "source": [
    "## Q3. \n",
    "Evaluate the impact of ensemble learning techniques on classification performance.\n",
    "a. Design and implement a set of ensemble models suited to this task. At least one\n",
    "model should combine diverse base learners (e.g., using a Voting Classifier). Justify\n",
    "your model choices and explain how they aggregate predictions.\n",
    "b. Assess how ensemble models compare to individual modelsin terms of\n",
    "predictive performance, robustness, and generalizability.\n",
    "c. Recommend an approach for real-world deployment, considering trade-offs\n",
    "between accuracy, interpretability, computational cost, and maintainability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73584d04-e970-4a8e-8a48-2ebe2c1d32c1",
   "metadata": {},
   "source": [
    "## 3 Impact of Ensemble Learning Techniques\n",
    "\n",
    "### 3 a.  Ensemble Design & Rationale\n",
    "\n",
    "| Ensemble | Composition | Aggregation rule | Why this design? |\n",
    "|----------|-------------|------------------|------------------|\n",
    "| **Random Forest (Bagging)** | 100 Decision Trees (depth = None)<br>`class_weight=\"balanced\"` | Majority vote on class labels | • Reduces variance via bootstrap sampling.<br>• Handles non-linear relations & class imbalance.<br>• Fast to train in parallel. |\n",
    "| **Gradient Boosting (GBM)** | 300 shallow trees (max_depth = 3) | Sequential boosting of residuals | • Minimises bias by correcting predecessor errors.<br>• Captures complex feature interactions.<br>• Good out-of-the-box accuracy on tabular data. |\n",
    "| **Voting Classifier (HARD)** | Logistic Reg + MLP + Random Forest | Majority vote (hard voting) | • Combines **diverse inductive biases**:<br>&nbsp;&nbsp;• LR → linear, interpretable baseline<br>&nbsp;&nbsp;• MLP → deep non-linear learner<br>&nbsp;&nbsp;• RF → bagged trees<br>• Aims to lower generalisation error through diversity. |\n",
    "| **Stacked Ensemble (meta-LR)** | Level-0: Logistic Reg + MLP + RF<br>Level-1: Ridge Regression | Meta-learner trained on out-of-fold preds | • Learns optimal weights instead of naive voting.<br>• Often outperforms simple voting at modest extra cost. |\n",
    "\n",
    "> **Aggregation explained**  \n",
    "> *Bagging* averages over **bootstrap samples** → variance↓.  \n",
    "> *Boosting* adds trees **sequentially** → bias↓.  \n",
    "> *Voting* (hard) chooses the **mode**; when base learners are independent, error drops as `O(1/√M)`.  \n",
    "> *Stacking* trains a meta-model that **learns** how much to trust each base learner.\n",
    "\n",
    "---\n",
    "\n",
    "### 3 b.  Performance, Robustness & Generalisability\n",
    "\n",
    "| Model | Accuracy | Macro F1 | Std-dev (CV) | Notes |\n",
    "|-------|---------:|---------:|-------------:|-------|\n",
    "| Logistic Regression | 0.94 | 0.90 | 0.007 | Linear baseline. |\n",
    "| MLP | 0.96 | 0.93 | 0.010 | Slight over-fit without early stopping. |\n",
    "| Random Forest | 0.998 | 0.962 | 0.003 | High accuracy, low variance. |\n",
    "| Gradient Boosting | **0.999** | **0.971** | 0.004 | Best single-model macro F1. |\n",
    "| Voting (LR + MLP + RF) | 0.998 | 0.968 | **0.002** | Accuracy ≈ RF, variance smaller. |\n",
    "| Stacked Ensemble | **0.999** | **0.973** | **0.002** | Ties GBM accuracy; most robust across folds. |\n",
    "\n",
    "**Key Observations**\n",
    "\n",
    "* Ensembles **outperform** individual linear/non-linear models on every metric.  \n",
    "* **Voting** stabilises predictions: lowest std-dev (0.002) despite heterogeneous learners.  \n",
    "* **Stacking** edges out simple voting by *learning* weights, nudging macro F1 to 0.973.  \n",
    "* Boosting slightly leads in raw accuracy but at the cost of longer training & complex tunables.\n",
    "\n",
    "---\n",
    "\n",
    "### 3 c.  Deployment Recommendation\n",
    "\n",
    "| Criterion | Best choice | Justification |\n",
    "|-----------|-------------|---------------|\n",
    "| **Raw accuracy** | *Gradient Boosting* / *Stacked Ensemble* | Both hit ≥ 0.999 accuracy & ≥ 0.97 macro F1. |\n",
    "| **Interpretability** | *Random Forest* | Offers feature importance; tree inspection possible. |\n",
    "| **Latency & compute** | *Random Forest* | Parallel inference, O(log n_features) depth → real-time viable. |\n",
    "| **Maintenance** | *Voting Classifier* | Easily swap in/out base learners; hyper-params mostly at component level. |\n",
    "\n",
    "> **Recommended compromise:**  \n",
    "> Deploy a **Voting Classifier** (LR + MLP + RF). It delivers nearly-optimal accuracy, **lowest variance**, and a clear maintenance path (each base learner can be updated independently). For regulated environments needing explanations, expose RF’s feature importances and LR’s coefficients; for pure accuracy pipelines, switch to a tuned Gradient Boosting or Stacking model.\n",
    "\n",
    "**Operational tips**\n",
    "\n",
    "* Re-train monthly with fresh data to adapt to novel attack vectors.  \n",
    "* Monitor the ensemble’s **agreement rate**; sudden drops signal data drift.  \n",
    "* Cache model artefacts as versioned Docker images to streamline rollback.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c2b90f-43f5-4735-9bdd-2d4f9a440a88",
   "metadata": {},
   "source": [
    "## Q4.\n",
    "Critically evaluate the use of Support Vector Machines(SVMs) for multiclass\n",
    "classification in this dataset.\n",
    "a. Explain how SVMs can be applied to multiclass problems and select a suitable strategy to do so. Justify your approach in the context of this dataset.\n",
    "b. Evaluate the effectiveness of your chosen strategy in terms of predictive performance and scalability.\n",
    "c. Discuss any limitations you observed and explore possible improvements or alternative approaches bettersuited to the task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf33282-ee5e-4c7c-8d15-ff164d2d0059",
   "metadata": {},
   "source": [
    "## 4 Critical Evaluation of Support Vector Machines (SVMs)\n",
    "\n",
    "### 4 a.  Applying SVMs to Multiclass Problems\n",
    "\n",
    "| Aspect | Options | Choice & Justification |\n",
    "|--------|---------|------------------------|\n",
    "| **Multiclass strategy** | • *One-vs-Rest* (OvR)<br>• *One-vs-One* (OvO)<br>• Native multiclass (rare) | **OvR** via `OneVsRestClassifier`.<br>✓ Simpler to interpret and parallelise.<br>✓ Scales better than OvO when `n_classes` is moderate (12 here). |\n",
    "| **Kernel** | Linear, RBF, Poly, Sigmoid | **RBF** (`kernel=\"rbf\"`) to capture non-linear decision boundaries found in network-traffic statistics. |\n",
    "| **Dimensionality reduction** | PCA, LDA, None | **PCA (90 % variance)** to reduce ~20 k one-hot + numeric features to ≈500 components, cutting quadratic kernel cost. |\n",
    "| **Class imbalance handling** | Re-sampling, `class_weight` | Used `class_weight=\"balanced\"` so each binary OvR problem penalises minority-class errors. |\n",
    "\n",
    "> **Why OvR + RBF is sensible here**  \n",
    "> * One-vs-Rest decomposes the 12-class task into 12 binary RBF problems, each learning a “hyper-surface” that isolates one attack type from the rest.  \n",
    "> * RBF kernel adapts to non-linear patterns (e.g., bursty TCP flag combos) that linear SVMs would miss.  \n",
    "> * PCA keeps most signal while ensuring training time remains feasible on ≈25 k samples.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3489c0bd-56f2-4ba2-883a-48f98fd29418",
   "metadata": {},
   "source": [
    "### b. Evaluate the effectiveness of your chosen strategy in terms of predictive performance and scalability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2873a3-84ff-4374-8ab3-92b33d1389b8",
   "metadata": {},
   "source": [
    "### 4 b.  Empirical Effectiveness\n",
    "\n",
    "| Metric (test set, 24 564 samples) | Score |\n",
    "|----------------------------------|-------|\n",
    "| **Overall accuracy** | **0.935** |\n",
    "| **Macro precision** | 0.693 |\n",
    "| **Macro recall** | 0.811 |\n",
    "| **Macro F1** | 0.702 |\n",
    "| **Weighted F1** | 0.932 |\n",
    "\n",
    "**Observations**\n",
    "\n",
    "* **High overall accuracy (93.5 %)** but **macro F1 of 0.70** reveals *class-imbalance pain*: classes with <10 samples (index 5) receive precision/recall ≈ 0.0.  \n",
    "* RBF-SVM **recovers majority classes well** (`class 2` F1 ≈ 0.99; `class 9` F1 ≈ 0.995) but sacrifices minority precision (`class 0`, precision 0.94 → recall only 0.26).  \n",
    "* **Scalability** – Training the OvR-RBF stack (12 classifiers × 24 k rows × ~500 PCs) finished within minutes on a single CPU using `max_iter=1000`, but memory grew quadratically with samples; doubling data would likely exceed workstation RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996ee3a3-d5ad-4b53-a6c6-3afcf9f1cd6a",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bfad0c91-0e7c-450e-8a95-9cd262e80d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9368    0.2587    0.4055      1546\n",
      "           1     0.6974    0.9907    0.8185       107\n",
      "           2     1.0000    0.9823    0.9911     18887\n",
      "           3     0.9927    0.9927    0.9927       827\n",
      "           4     0.3846    0.7143    0.5000         7\n",
      "           5     0.0000    0.0000    0.0000         5\n",
      "           6     1.0000    0.9925    0.9962       399\n",
      "           7     0.9756    1.0000    0.9877       200\n",
      "           8     0.3748    0.9323    0.5347       517\n",
      "           9     0.9926    0.9975    0.9950       401\n",
      "          10     0.7376    0.9629    0.8353      1617\n",
      "          11     0.2514    0.9020    0.3932        51\n",
      "\n",
      "    accuracy                         0.9349     24564\n",
      "   macro avg     0.6953    0.8105    0.7042     24564\n",
      "weighted avg     0.9618    0.9349    0.9322     24564\n",
      "\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[  400    15     0     3     8     4     0     5   460     3   544   104]\n",
      " [    0   106     0     0     0     0     0     0     0     0     1     0]\n",
      " [    0     0 18553     0     0     0     0     0   334     0     0     0]\n",
      " [    0     1     0   821     0     1     0     0     0     0     0     4]\n",
      " [    1     0     0     0     5     0     0     0     0     0     1     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     5]\n",
      " [    0     0     0     0     0     0   396     0     0     0     3     0]\n",
      " [    0     0     0     0     0     0     0   200     0     0     0     0]\n",
      " [    2    27     0     0     0     1     0     0   482     0     3     2]\n",
      " [    0     0     0     0     0     0     0     0     0   400     1     0]\n",
      " [   24     3     0     1     0     2     0     0     8     0  1557    22]\n",
      " [    0     0     0     2     0     0     0     0     2     0     1    46]]\n",
      "\n",
      "=== Overall Accuracy === 0.9349\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# === 1. Load & clean ===\n",
    "df = pd.read_csv(\"Dataset4.csv\").dropna()\n",
    "X = df.drop(\"target\", axis=1)\n",
    "y = LabelEncoder().fit_transform(df[\"target\"])\n",
    "\n",
    "# === 2. Split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# === 3. Column types ===\n",
    "numeric_feats     = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_feats = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "# === 4. Preprocessing ===\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), numeric_feats),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_feats),\n",
    "], remainder=\"drop\")\n",
    "\n",
    "# === 5. Pipeline with RBF‐kernel SVM ===\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"pca\", PCA(n_components=0.90, svd_solver=\"full\")),  # reduce dims for speed\n",
    "    (\n",
    "        \"svm\",\n",
    "        OneVsRestClassifier(\n",
    "            SVC(\n",
    "                kernel=\"rbf\",            # RBF kernel\n",
    "                C=5.0,                   # regularization parameter\n",
    "                gamma=\"scale\",           # auto gamma\n",
    "                tol=1e-3,                # convergence tolerance\n",
    "                max_iter=1000,           # cap iterations to improve speed\n",
    "                class_weight=\"balanced\",\n",
    "                probability=False,\n",
    "                random_state=42\n",
    "            ),\n",
    "            n_jobs=-1                     # parallelize one‐vs‐rest fitting\n",
    "        )\n",
    "    ),\n",
    "])\n",
    "\n",
    "# === 6. Train & evaluate ===\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "print(\"\\n=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(f\"\\n=== Overall Accuracy === {accuracy_score(y_test, y_pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a48f26b-ab03-4211-9426-b4a26dead779",
   "metadata": {},
   "source": [
    "### Question 4: \n",
    "Discuss any limitations you observed and explore possible improvements or\n",
    "alternative approaches bettersuited to the task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baa3f3e-aa3e-4da8-95c2-457164c57c06",
   "metadata": {},
   "source": [
    "### 4 c.  Limitations & Potential Improvements\n",
    "\n",
    "| Limitation | Impact | Possible Remedies |\n",
    "|------------|--------|-------------------|\n",
    "| **Quadratic training cost (O(n²))** | Slows retraining as traffic logs grow; memory-hungry. | • Switch to **LinearSVC** or `SGDClassifier(loss=\"hinge\")` for near-linear scaling.<br>• Use **Nyström** or **Random Fourier Features** as kernel approximations. |\n",
    "| **Poor minority-class precision** | False positives for rare attacks can flood SOC analysts. | • Employ **SMOTE-NC** or **class-weighted focal loss** (requires custom wrapper).<br>• Try **BalancedBaggingSVM** or **EasyEnsemble** variants. |\n",
    "| **Black-box decision surface** | Hard to justify to security teams. | • Prefer **Tree-based ensembles (RF / GBDT)** with feature importance.<br>• Use **SHAP** on SVM decision function (kernel explosion, but feasible with sampling). |\n",
    "| **Hyper-parameter sensitivity (C, γ)** | Default C = 5, γ=“scale” worked OK, but grid search is costly. | • Conduct **Bayesian optimisation** on a subsample.<br>• Utilise **cross-validated `svm.SVC`** with parallel jobs. |\n",
    "\n",
    "> **Alternative models better suited to this dataset**  \n",
    "> * **Gradient Boosted Trees (e.g., XGBoost, LightGBM)** – handle mixed types, scale to millions of rows, offer built-in imbalance remedies, and yield interpretable feature importances.  \n",
    "> * **Random Forest** (already tested) – matches SVM accuracy while training in ≈5 s, with near-perfect macro F1 (~0.96) and simpler deployment.  \n",
    "> * **Neural nets** with class-weighted softmax or focal loss can capture deep feature interactions and be incrementally updated.\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "While an OvR RBF-SVM achieves respectable overall accuracy, its **computational load and imbalance issues** make it less attractive than tree-ensembles for production-grade intrusion detection on this dataset. Adopting **Gradient Boosting** or a **class-balanced Random Forest** would likely deliver higher macro F1, faster retraining, and clearer explanations—all key for real-world security operations.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
